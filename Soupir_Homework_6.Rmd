---
title: "Homework 6"
author: "Alex Soupir"
date: "October 20, 2019"
output:
  pdf_document:
    keep_md: true
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=F,warning=F,echo=F,fig_height=10,fig_width=7,cache = F)
```

*Packages*: HSAUR3, mgcv, GGally, mboost, rpart, wordcloud, ggplot2, TH.data, tidyverse, gamair

*Collaborators*: Ajay Gupta, James Young

Please do the following problems from the text book R Handbook and stated.

1. Consider the body fat data introduced in Chapter 9 (\textbf{ bodyfat} data from \textbf{TH.data}  package).  

    a) Explore the data graphically. What variables do you think need to be included for predicting bodyfat? (Hint: Are        there correlated predictors).
    
    ```{r, echo=FALSE}
    library("HSAUR3")
    library("mgcv")
    library("GGally")
    library("mboost")
    library("rpart")
    library("wordcloud")
    library("ggplot2")
    library("TH.data")
    
    set.seed(333)
    data(bodyfat)
    bdft = bodyfat
    
    pairs(bdft)
    ggpairs(bdft, colour=2, alpha=0.4)
    ```
    
    **As with last weeks assignment, there are a few variables that appear to be highly correlated to each other. The suggestion was to remove these because of the negative impact that highly correlated variables can have. Anthro4 is highly correlated with anthro3a and anthro3b and anthro3a is also highly correlated with anthro3b.**
    
    ```{r, echo=FALSE}
    set.seed(333)
    library(tidyverse)
    bdft = bodyfat
    
    DEXfat = bdft$DEXfat
    ft = bdft[,!names(bdft) %in% "DEXfat"]
    
    correlations = cor(ft)
    correlations[lower.tri(correlations)] = 0
    diag(correlations) = 0
    
    bdft = ft[,!apply(correlations,2,function(x) any(x > abs(0.94)))]
    bdft = cbind(bdft, DEXfat)
    bdft2 = ft[,!apply(correlations,2,function(x) any(x > abs(0.80)))]
    
    cat("Features selected after removing variables correlated greater than 0.94: \n")
    features = colnames(bdft)
    features
    
    cat("\nFeatures selected after removing variables correlated greater than 0.80: \n")
    colnames(bdft2)
    ```
    
    **Discussion - Since we want to have both waistcirc, anthro3c, and hipcirc in part b, the threshold for correlation elimination was set to 0.94 to remove those that are highly correlated while maintaining these 3 features (anthro3c has a correlation of 0.933 with anthro3b, so I set the threshold slightly higher). The variables that I think need to be included for predicting bodyfat given the above is *age*, *waistcirc*, *hipcirc*, *elbowbreadth*, *kneebreadth*, *anthro3a*, and *DEXfat*. If the threshold was set lower to remove more highly correlated values (correlations greater than 0.8), I think *age*, *waistcirc*, *elbowbreadth*, *kneebreadth*, and *anthro3a* would be important to use without having built any model yet.**
    
    b) Fit a generalised additive model assuming normal errors using the following code. 

       \begin{verbatim}
         bodyfat_gam <- gam(DEXfat~ s(age) + s(waistcirc) + s(hipcirc) + 
                  s(elbowbreadth) + s(kneebreadth)+ s(anthro3a) +
                  s(anthro3c), data = bodyfat)
       \end{verbatim}
      
        - Assess the \textbf{summary()} and \textbf{plot()} of the model (don't need GGPLOT). Are all covariates informative? Should all covariates be smoothed or should some be included as a linear effect? 
        
        - Report GCV, AIC, adj-R$^2$, and total model degrees of freedom. 
        
        - Use \textbf{gam.check()} function to look at the diagnostic plot. Does it appear that the normality assumption is violated? 
        
        - Write a discussion on all of the above points.
        
    ```{r, echo=FALSE}
    set.seed(333)
    bodyfat_gam = gam(DEXfat ~ s(age) + s(waistcirc) + s(hipcirc) + s(elbowbreadth) + s(kneebreadth) + s(anthro3a) + s(anthro3c), data = bdft)
    summary(bodyfat_gam)
    
    par(mfrow=c(2,4))
    plot(bodyfat_gam, select = 1)
    plot(bodyfat_gam, select = 2)
    plot(bodyfat_gam, select = 3)
    plot(bodyfat_gam, select = 4)
    plot(bodyfat_gam, select = 5)
    plot(bodyfat_gam, select = 6)
    plot(bodyfat_gam, select = 7)
    
    par(mfrow=c(2,2))
    gam.check(bodyfat_gam)
    
    cat("\nModel GVC: \n")
    bdft_gvc = bodyfat_gam$gcv.ubre
    unname(bdft_gvc)
    
    cat("\nModel AIC: \n")
    bdft_aic = AIC(bodyfat_gam)
    bdft_aic
    
    cat("\nModel R^2: \n")
    bdft_r2 = summary(bodyfat_gam)$r.sq
    bdft_r2
    
    cat("\nEstimated Degrees of Freedom: \n")
    bdft_df = sum(influence(bodyfat_gam))
    bdft_df-1
    
    gam1 = c(unname(bdft_gvc), bdft_aic, bdft_r2, bdft_df-1)
    ```
    
    **Discussion - GCV = 8.44, AIC = 345.71, adj-R$^2$ = 0.95, model degrees of freedom = 22.57 (including 1 df for intercept as per stackexchange, or 21.57 not including 1 for the intercept).Variables *age*, *elbowbreadth*, and *anthro3c* are not significant at p = 0.05. Variables *age*, *waistcirc*, *elbowbreadth*, and *anthro3a* have an estimated degrees of freedom of 1 while *kneebreadth* has an edf of 8.754. Comparing these values to the plot, the higher the degrees of freedom the less linear the smoothed {s()} variable is, so *age*, *waistcirc*, *elbowbreadth*, and *anthro3a* could be included as a linear effect. The models generalized cross-validation score (GCV) is 8.44 and AIC is 345.71 on 21.57 degrees of freedom. The GCV and AIC most likely could be improved through feature selection than smoothing those features in the generalized additive model, but without another model to compare to it cannot be determined if this is a good model or poor model. Using *gamcheck()* to look at the residual plots, the assumption of normality doesn't appear to be violated. The histogram shows that a couple residuals are greater than 4, but as a whole do not appear to violate the assumption.**
    
    c) Now remove insignificant variables and remove smoothing for some variables. Report the summary, plot, GCV, AIC,         adj-R$^2$.
      
      \begin{verbatim}
        bodyfat_gam2 <- gam(DEXfat~ waistcirc + s(hipcirc) + 
                     s(kneebreadth)+ anthro3a +
                     s(anthro3c), data = bodyfat)
      \end{verbatim}
    
    ```{r, echo=FALSE}
    set.seed(333)
    cat("Given Model: \n")
    bodyfat_gam2 <- gam(DEXfat~ waistcirc + s(hipcirc) + s(kneebreadth)+ anthro3a + s(anthro3c), data = bdft)
    summary(bodyfat_gam2)
    
    par(mfrow=c(1,3))
    plot(bodyfat_gam2, select = 1)
    plot(bodyfat_gam2, select = 2)
    plot(bodyfat_gam2, select = 3)
    
    par(mfrow=c(2,2))
    gam.check(bodyfat_gam2)
    
    cat("\nModel GVC: \n")
    bdft_gvc = bodyfat_gam2$gcv.ubre
    unname(bdft_gvc)
    
    cat("\nModel AIC: \n")
    bdft_aic = AIC(bodyfat_gam2)
    bdft_aic
    
    cat("\nModel R^2: \n")
    bdft_r2 = summary(bodyfat_gam2)$r.sq
    bdft_r2
    
    cat("\nEstimated Degrees of Freedom: \n")
    bdft_df = sum(influence(bodyfat_gam2))
    bdft_df-1
    
    gam2 = c(unname(bdft_gvc), bdft_aic, bdft_r2, bdft_df-1)
    ```
    
    **Discussion - GCV = 7.95, AIC = 343.26, adj-R$^2$ = 0.95. All variable terms were significant at alpha = 0.05 and the intercept was significant at alpha = 0.1 level. The generalized cross-validation score was better than that of the previous model at 7.95 instead of 8.44. The AIC of the model with only including the significant variables from the previous model decreased slightly which indicates that the new model performs better. However, the adj-R$^2$ increased by 0.001**
    
    d) Again fit an additive model to the body fat data, but this time for a log-transformed response. Compare the three        models, which one is more appropriate? (Hint: use Adj-R$^2$, residual plots, etc. to compare models).
    
    ```{r, echo=FALSE}
    set.seed(333)
    bodyfat_gam3 = gam(log(DEXfat) ~ waistcirc + s(hipcirc) + s(kneebreadth)+ anthro3a + s(anthro3c), data = bdft)
    summary(bodyfat_gam3)
    
    par(mfrow=c(1,3))
    plot(bodyfat_gam3, select = 1)
    plot(bodyfat_gam3, select = 2)
    plot(bodyfat_gam3, select = 3)
    
    cat("\nPart B Model: \n")
    par(mfrow=c(2,2))
    gam.check(bodyfat_gam)
    cat("\nPart C Model: \n")
    par(mfrow=c(2,2))
    gam.check(bodyfat_gam2)
    cat("\nPart D Model: \n")
    par(mfrow=c(2,2))
    gam.check(bodyfat_gam3)
    
    cat("\nModel GVC: \n")
    bdft_gvc = bodyfat_gam3$gcv.ubre
    unname(bdft_gvc)
    
    cat("\nModel AIC: \n")
    bdft_aic = AIC(bodyfat_gam3)
    bdft_aic
    
    cat("\nModel R^2: \n")
    bdft_r2 = summary(bodyfat_gam3)$r.sq
    bdft_r2
    
    cat("\nEstimated Degrees of Freedom: \n")
    bdft_df = sum(influence(bodyfat_gam3))
    bdft_df-1
    
    gam3 = c(unname(bdft_gvc), bdft_aic, bdft_r2, bdft_df-1)
    
    modeltable = data.frame("Metric" =c("GCV","AIC","Adj R-Sqrd","Degrees of Freedom"),
                            "Part B Model" = gam1,
                            "Signif Variables" = gam2,
                            "Log Response Model" = format(gam3, scientific = F))
    modeltable
    ```
    
    **Discussion - The log transformed response variable decreases the generalized cross-validation score and the AIC of the model which indicates that log transforming the response variable creates a better model than not log tranforming it. The log transformation of the response variable produces a GCV of 0.009 AIC of -136.5 with an estimated 15.6 degrees of freedom. The smoothing of the kneebreadth variable isn't significant at alpha=0.05 now too. The degrees of freedom was also decreased from smoothing using the log transformation of the same model as Part C from an estimated 19.5 to 14.6 DoF. The adj-R$^2$ was slightly less than non-log transformed DEXfat, but only 0.001 less.**
    
    e) Fit a generalised additive model that underwent AIC-based variable selection (fitted using function \textbf{             gamboost()} function). What variable was removed by using AIC? 
      \begin{verbatim}
       bodyfat_boost <- gamboost(DEXfat~., data = bodyfat)
       bodyfat_aic <- AIC(bodyfat_boost)
       bf_gam <- bodyfat_boost[mstop(bodyfat_aic)]
      \end{verbatim}
    
    ```{r, echo=FALSE}
    set.seed(333)
    bodyfat_boost = gamboost(DEXfat ~., data=bodyfat)
    bodyfat_aic = AIC(bodyfat_boost)
    bf_gam = bodyfat_boost[mstop(bodyfat_aic)]
    
    summary(bodyfat_boost)
    ```
    
    **Discussion - The variables that were used through the selection are *waistcirc*, *hipcirc*, *elbowbreadth*, *kneebreadth*, *anthro3a*, *anthro3b*, *anthro3c*, and *anthro4*. This shows that the variable that was eliminated using AIC was the *age* variable.**
    
2. Fit a logistic additive model to the glaucoma data. (Here use family = "binomial"). Which covariates should enter the model and how is their influence on the probability of suffering from glaucoma? (Hint: since there are many covariates, use \textbf{gamboost()} to fit the GAM model.)

```{r, echo=FALSE}
set.seed(333)
glau = GlaucomaM
glau_boost = gamboost(Class~., data=glau, family=Binomial())
summary(glau_boost)

preds = predict(glau_boost,type="response")
obs = ifelse(glau$Class == "normal",1,0)
preds2 = ifelse(preds > 0.5, 1 ,0)

cat("\nMeans Squared Error of Predictions on Glaucoma DF using Boost Model: \n")
mean((preds2 - obs)^2)

Class_calc <- ifelse(preds2 == 1, "normal", "glaucoma")
#confusion matrix
confmat = table(GlaucomaM$Class, Class_calc)

cat("\nError rate of gamboost fitted model: \n")
(sum(confmat)-(sum(diag(confmat))))/sum(confmat)

layout(matrix(1:6, ncol = 3))
plot(glau_boost)

glau_model2 = gam(obs ~ s(as, k=3) + hic + s(mhcn, k=3) + s(abrs, k=3) + s(mhcg, k=3) + s(mhci, k=3) + phcg + phci + s(vass, k=3) + s(phcn, k=3) + s(hvc, k=3) + s(vars, k=3) + s(vari, k=3) + mdi + s(tmi, k=3) + s(mdn, k=3) + s(tms, k=3) + s(mv, k=3), data=glau, family=binomial())
summary(glau_model2)

preds3 = predict(glau_model2,type="response")
preds3 = ifelse(preds3 > 0.5, 1, 0)
cat("\nMSE of rebuilt Model using variables given by gamboost: \n")
mean((preds3-obs)^2)
cat("\nError rate of rebuilt model: \n")
Class_cal = ifelse(preds3 == 1, "normal", "glaucoma")
confmat2 = table(GlaucomaM$Class, Class_cal)
(sum(confmat2)-(sum(diag(confmat2))))/sum(confmat2)
confmat2
```

**Discussion - The variable selected using *gamboost()* are *tmi*, *mhcg*, *vars*, *mhci*, *hvc*, *vass*, *as*, *vari*, *mv*, *abrs*, *mhcn*, *phcn*, *mdn*, *phci*, *hic*, *phcg*, *mdi*, and *tms*. Using these variables, the classification error of the model (error and MSE = 0.102) is lower than that of the all models created last week for the glaucoma data set except the adaptive boosting on the whole data which perfectly fit the model. A train test split of 80/20 resulted in an error (MSE was the same value as the error) of 0.195, whereas gam boosting on the data produced an MSE of 0.10. This means that the variables are better able to predict whether a patient has glaucoma or not than k-fold cross validation (k-10, MSE=0.27) and glm (MSE=0.48). Creating another model to allow for a nice summary of the variables, we can see that *mhcn*, *phcn*, *vars*, *vari*, *mdn* and *tms* aren't significant.**

3. Investigate the use of different types of scatterplot smoothers on the Hubble data from Chapter 6. (Hint: follow the example on men1500m data scattersmoothers page 199 of Handbook).

```{r, echo=FALSE}
library(gamair)
data(hubble)
hub=hubble
hub = hub[order(hub$x),]
x = hub$x
y = hub$y
hub_lowess = lowess(x,y)
par(mfrow=c(2,2))
plot(y ~ x, data=hub, xlab="Distance (Mega parsecs)", ylab="Relative Velocity (km/s)", main="Scatter Plot with Lowess Smoothing Function")
lines(hub_lowess)
x = hub$x
y = hub$y
hub_cubic = gam(y~s(x, bs="cr"))
plot(y ~ x, data=hub, xlab="Distance (Mega parsecs)", ylab="Relative Velocity (km/s)", main="Scatter Plot with Cubic Smoothing function")
lines(x,predict(hub_cubic))
hub_lm = lm(y~x,data=hub)
plot(y ~ x, data=hub, xlab="Distance (Mega parsecs)", ylab="Relative Velocity (km/s)", main="Scatter Plot with Simple Linear Regression")
abline(hub_lm)
hub_quad = lm(y~x+I(x^2), data=hub)
hub_quad_preds = predict(hub_quad)
plot(y ~ x, data=hub, xlab="Distance (Mega parsecs)", ylab="Relative Velocity (km/s)", main="Scatter Plot with Quadratic Model")
lines(hubble$x[order(hubble$x)],hub_quad_preds[order(hub_quad_preds)])

library(gridExtra)
#ggplot lowess smoothing
b<-ggplot(data = hubble, aes(x = x, y = y))+ geom_point()+labs(y = "Galaxy velocity \n(Km/sec)", x = "Galaxy distnace \n(Mega parsec)", title   = "Lowess Smoothing")+ geom_line(data=hub, aes(x=hub_lowess$x, y = hub_lowess$y), color="blue", size=1)
#ggplot cubic smoothiung
c<-ggplot(data = hubble, aes(x = x, y = y))+ geom_point()+labs(y = "Galaxy velocity", x = "Galaxy distnace", title   = "Cubic Smoothing") + stat_smooth (method ="gam", formula = y ~ s(x), se = F, color="blue")
#ggplot linear regression
a<-ggplot(data = hubble, aes(x = x, y = y))+ geom_point()+labs(y = "Galaxy velocity", x = "Galaxy distnace", title   = "Linear regression")+ geom_smooth(method = 'lm', formula = y~x, se = F, color="blue")
#ggplot quadratic regression
d<-ggplot(data = hubble, aes(x = x, y = y))+ geom_point()+labs(y = "Galaxy velocity", x = "Galaxy distnace", title   = "Quadratic regression") + geom_smooth(method = "lm", formula = y~x+I(x^2), se =F, color="blue")
grid.arrange(b,c, a,d)
```

**Discussion - I used 4 different scatter plot models with the hubble data using the example from the handbook. The linear model is as expected and previously seen in homework. The Lowess smoothing shows a couple seemingly sharp changes in direction while the quadratic and cubic smoothing models are less abrupt while still appearing to fit the data decently.**

*Resources Used*:

+ stat.ethz.ch
+ rdocumentation.org
+ stackexchange.com
+ Homework 5


